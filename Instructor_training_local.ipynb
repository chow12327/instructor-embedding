{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o55aDSe4-4qf"
      },
      "source": [
        "Reproduction of experiments for InstructOR Embeddings on classification of sentences by training GTR base on MEDI wiki data:\n",
        "\n",
        "Steps to run the experiment:\n",
        "\n",
        "Step 1: Update parameters in the code cell for training. The following parameters can be adjusted:\n",
        "\n",
        "\n",
        "1. Seed (seed)\n",
        "2. Batch Size (batch_size)\n",
        "3. Training Samples/label for logistic regression (samples_per_label)\n",
        "4. Number of Experiments per dataset (n_experiment)\n",
        "\n",
        "Step 2: Run all\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OOvbeixHqe1a",
        "outputId": "8538a45f-d794-423a-db49-7041a6147cd6"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/chow12327/instructor-embedding.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "trDBo1UMq2Lp",
        "outputId": "eed958de-90c1-42f7-b4fa-6c2f32bb706b"
      },
      "outputs": [],
      "source": [
        "!pip install -r /content/instructor-embedding/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5MLZ9h06Rp_",
        "outputId": "55e6c40f-de2c-46fa-adb1-962bb0a42d0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nltk_data] Error loading punkt: <urlopen error [SSL:\n",
            "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed:\n",
            "[nltk_data]     unable to get local issuer certificate (_ssl.c:1129)>\n",
            "Downloading: 100%|██████████████████████████████| 411/411 [00:00<00:00, 293kB/s]\n",
            "Downloading: 100%|█████████████████████████████| 804/804 [00:00<00:00, 4.08MB/s]\n",
            "Downloading: 100%|█████████████████████████| 4.98M/4.98M [00:00<00:00, 31.9MB/s]\n",
            "Downloading: 100%|█████████████████████████| 9.18M/9.18M [00:00<00:00, 25.8MB/s]\n",
            "Downloading: 100%|██████████████████████████████| 112/112 [00:00<00:00, 758kB/s]\n",
            "There are 35000 pairs to train in total.\n",
            "Downloading .gitattributes: 100%|███████████| 1.22k/1.22k [00:00<00:00, 197kB/s]\n",
            "Downloading 1_Pooling/config.json: 100%|████████| 191/191 [00:00<00:00, 241kB/s]\n",
            "Downloading README.md: 100%|███████████████| 1.85k/1.85k [00:00<00:00, 2.32MB/s]\n",
            "Downloading config.json: 100%|█████████████████| 804/804 [00:00<00:00, 1.03MB/s]\n",
            "Downloading (…)ce_transformers.json: 100%|██████| 122/122 [00:00<00:00, 159kB/s]\n",
            "Downloading pytorch_model.bin: 100%|███████| 1.89G/1.89G [00:40<00:00, 46.3MB/s]\n",
            "Downloading (…)nce_bert_config.json: 100%|███| 53.0/53.0 [00:00<00:00, 25.4kB/s]\n",
            "Downloading (…)cial_tokens_map.json: 100%|█████| 112/112 [00:00<00:00, 54.3kB/s]\n",
            "Downloading tokenizer.json: 100%|██████████| 9.62M/9.62M [00:00<00:00, 47.9MB/s]\n",
            "Downloading tokenizer_config.json: 100%|████████| 411/411 [00:00<00:00, 161kB/s]\n",
            "Downloading vocab.txt: 100%|███████████████| 5.22M/5.22M [00:00<00:00, 41.3MB/s]\n",
            "Downloading modules.json: 100%|█████████████████| 349/349 [00:00<00:00, 144kB/s]\n",
            "load INSTRUCTOR_Transformer\n",
            "max_seq_length  256\n",
            "Running tokenizer on train dataset: 100%|█| 35000/35000 [02:05<00:00, 277.99 exa\n",
            "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "[INFO|trainer.py:1516] 2023-11-21 02:42:30,826 >> ***** Running training *****\n",
            "[INFO|trainer.py:1517] 2023-11-21 02:42:30,826 >>   Num examples = 35000\n",
            "[INFO|trainer.py:1518] 2023-11-21 02:42:30,826 >>   Num Epochs = 1\n",
            "[INFO|trainer.py:1519] 2023-11-21 02:42:30,826 >>   Instantaneous batch size per device = 8\n",
            "[INFO|trainer.py:1520] 2023-11-21 02:42:30,826 >>   Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "[INFO|trainer.py:1521] 2023-11-21 02:42:30,826 >>   Gradient Accumulation steps = 1\n",
            "[INFO|trainer.py:1522] 2023-11-21 02:42:30,826 >>   Total optimization steps = 4375\n",
            "  0%|                                                  | 0/4375 [00:00<?, ?it/s]^C\n"
          ]
        }
      ],
      "source": [
        "#Seed - Default seed generated by code. They use manual seed to generate a seed.\n",
        "#Learning Rate - 2e-4\n",
        "#AdamW Warmup Rate: 0.2\n",
        "\n",
        "!python3 train.py --model_name_or_path sentence-transformers/use-cmlm-multilingual --output_dir outputs_l2e_4  --cache_dir train_cache/ --max_source_length 512 --num_train_epochs 1 --save_steps 2000 --cl_temperature 0.1 --warmup_ratio 0.2 --learning_rate 2e-4 --overwrite_output_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iuXu8Pkt2JVo"
      },
      "outputs": [],
      "source": [
        "#Author provided parameters\n",
        "#Seed - Default seed generated by code. They use manual seed to generate a seed.\n",
        "#Learning Rate - 2e-5\n",
        "#AdamW Warmup Rate: 0.1\n",
        "\n",
        "!python instructor-embedding/train.py --model_name_or_path sentence-transformers/gtr-t5-base --output_dir outputs_l2e5  --cache_dir instructor-embedding/train_cache/ --max_source_length 512 --num_train_epochs 1 --save_steps 2000 --cl_temperature 0.1 --warmup_ratio 0.1 --learning_rate 2e-5 --overwrite_output_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPAVH-Ck2RlW",
        "outputId": "b741be34-d497-4a16-9447-b045c6d66bef"
      },
      "outputs": [],
      "source": [
        "#Different seed\n",
        "#Seed - 30\n",
        "#Learning Rate - 2e-5\n",
        "#AdamW Warmup Rate: 0.1\n",
        "\n",
        "!python instructor-embedding/train.py --model_name_or_path sentence-transformers/gtr-t5-base --output_dir outputs_seed30_l2e5  --cache_dir instructor-embedding/train_cache/ --max_source_length 512 --num_train_epochs 1 --save_steps 2000 --cl_temperature 0.1 --warmup_ratio 0.1  --data_seed 30 --learning_rate 2e-5 --overwrite_output_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYfhSUSi237e",
        "outputId": "aac8b0e3-af0d-4f5a-8b92-616c30262f8a"
      },
      "outputs": [],
      "source": [
        "#Different seed\n",
        "#Seed - 30\n",
        "#Learning Rate - 2e-4\n",
        "#AdamW Warmup Rate: 0.2\n",
        "\n",
        "!python instructor-embedding/train.py --model_name_or_path sentence-transformers/gtr-t5-base --output_dir outputs_seed30_l2e5  --cache_dir instructor-embedding/train_cache/ --max_source_length 512 --num_train_epochs 1 --save_steps 2000 --cl_temperature 0.1 --warmup_ratio 0.2 --data_seed 30 --learning_rate 2e-4 --overwrite_output_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfXmMXcxBLqr",
        "outputId": "35973d02-07e5-469c-c0e8-c9b054c15426"
      },
      "outputs": [],
      "source": [
        "#provide multiple parameter values here.\n",
        "\n",
        "#Evaluation after training - update model_name parameter with directory name\n",
        "\n",
        "seeds = [120]\n",
        "batchsizes = [16]\n",
        "samplesperlabels = [16]\n",
        "\n",
        "for seed in seeds:\n",
        "  for batch_size in batchsizes:\n",
        "      for samplesperlabel in samplesperlabels:\n",
        "        !python  instructor-embedding/evaluation/MTEB/examples/evaluate_model.py --model_name outputs_seed30_l2e5/ --output_dir outputs --task_name 'EmotionClassification' --result_file results --batch_size {batch_size} --samples_per_label {samplesperlabel} --n_experiments 5 --seed {seed}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EiASp0ia44ci",
        "outputId": "81d3939d-d004-47c0-c60e-43754e902496"
      },
      "outputs": [],
      "source": [
        "#provide multiple parameter values here.\n",
        "\n",
        "#Evaluation after training - update model_name parameter with directory name\n",
        "\n",
        "seeds = [120]\n",
        "batchsizes = [32]\n",
        "samplesperlabels = [8]\n",
        "\n",
        "for seed in seeds:\n",
        "  for batch_size in batchsizes:\n",
        "      for samplesperlabel in samplesperlabels:\n",
        "        !python  instructor-embedding/evaluation/MTEB/examples/evaluate_model.py --model_name outputs_seed30_l2e5/ --output_dir outputs --task_name 'MTOPDomainClassification' --result_file results --batch_size {batch_size} --samples_per_label {samplesperlabel} --n_experiments 5 --seed {seed}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FrK10MQNGrHP",
        "outputId": "a602bec5-326b-4abc-d9ad-dc07d74368d3"
      },
      "outputs": [],
      "source": [
        "# !zip -r outputs_seed30_l2e4.zip outputs_seed30_l2e5 -x outputs_seed30_l2e5/checkpoint-4000/* -x outputs_seed30_l2e5/checkpoint-2000/*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cjYgKiSGYp0",
        "outputId": "285e4fac-dcdf-4654-cd40-dd4714db3a19"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "XwG_RJ18HwS2",
        "outputId": "3da06a5e-c64b-4ec2-d111-fa1afae13eda"
      },
      "outputs": [],
      "source": [
        "# from google.colab import files\n",
        "# import shutil\n",
        "# shutil.copy('outputs_seed30_l2e4.zip','/content/gdrive/MyDrive/')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
